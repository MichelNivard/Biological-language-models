# Scale up Training {.unnumbered}

This chapter isn't a part of the "DNA" section of the book, because the lessons are really quite general, but it comes after because we needed a little bit of experience with language model training before even considering training a serious model. This is also a somewhat awkward chapter for me to write, especially for the part of the readership that has a background in ML. See, I am a psychologist by training (though I have worked in genetic epidemiology for years and years), and while a lot of my academic work is fairly computational, I am no expert in language model scaling by any means! Remember, the preamble to the book explains this book is an account of me learning about biological language models and taking others along for the ride, not an authoritative text!

## Don't Try to Win the Compute Race

Among the DNA models I could find on Hugging Face is a 7B parameter model like <https://huggingface.co/genbio-ai/AIDO.DNA-7B>. AIDO is trained on "256 H100 GPUs" in "8 days". The training data consisted of 10.6 billion bases. That's not even a particularly large model in the grand scheme of things, but if you consider a cost of ±$2 per hour per H100, you are going to spend $100k. Obviously, there are academic compute resources you can get access to by appointment or based on fair use at your institute, university, or through collaborative national infrastructure, but even those are finite.

You have to consider feasibility. Today (March 2025), the Dutch national computer cluster for research (Snellius at SURF Sara) has 88 nodes with 4 H100 GPUs and 72 nodes with 4 A100 GPUs. TACC, the University of Texas at Austin compute provider, has ±80 A100 nodes (each with 3 GPUs). Those are two examples of reasonably well-funded HPC providers in academia. In my experience, you could get time reserved for your research at your local academic HPC provider at steep discounts, and these systems are likely large enough to train that 7B model I linked to. However, note how on either TACC or Snellius, 256 GPUs for 8 days would block the entire system for over a week. Perhaps you could apply for access to larger national research clusters, like [Isambard-AI](https://www.bristol.ac.uk/news/2023/november/supercomputer-announcement.html) in the UK (being built in Bristol right now, a motivation for me to write this) which has 5,000 H200 GPUs. However, in general, it is likely you are going to be relatively compute constrained. Don't be discouraged though—most breakthroughs are not going to be compute-based, and there are immense efficiency gains to be made that will level the playing field.

## Smart Architectures

In Chapter 4, we studied smarter, DNA-specific model architectures. The GPN model inspired by @Benegas2024 we introduced can blow away a standard BERT in an hour of training on my 2022 MacBook Air (the BERT we trained and compared to our GPN-BERT trained for ±8 hours on a strong GPU). The massive efficiency gain may mean you can beat the 7B BERT-like model we took as an example of compute costs with a fraction of the compute! Other researchers have designed alternatives for the transformer module at the core of these models with DNA in mind and expanded its context window up to 1 million bases with far less compute [@nguyen2023]. These models can be mixed and matched for further gains.

## Optimize, Optimize, Optimize

## Parallel Training