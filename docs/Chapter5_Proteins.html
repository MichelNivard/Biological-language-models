<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>11&nbsp; Integrated protein diffusion language models – Biological Language Models &amp; Neural Networks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./summary.html" rel="next">
<link href="./Chapter4_Proteins.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e84559ba8659b1a571faa725acb99328.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="site_libs/viz-1.8.2/viz.js"></script>
<link href="site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="site_libs/grViz-binding-1.0.11/grViz.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./DNA.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Biological Language Models &amp; Neural Networks</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter1_Proteins.html">Proteins</a></li><li class="breadcrumb-item"><a href="./Chapter5_Proteins.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Integrated protein diffusion language models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Preamble1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is this Book About?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Preamble2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Read this Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Preamble3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The software stack</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">DNA</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter1_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preparing DNA data for training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter2_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Training our first DNA Language Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter3_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Evaluating DNA Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter4_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Evolution-Aware Encoders</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter5_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Weaving Together Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter6_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">A Review of Current DNA Language Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Scaling_training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Scale up Training</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Proteins</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter1_Proteins.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Proteins: from sequence to structure</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter2_Proteins.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Selecting and curating protein sequences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter3_Proteins.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Training our first Protein Language Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter4_Proteins.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Protein contact maps from attention maps</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter5_Proteins.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Integrated protein diffusion language models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Multi-Modal-Biology</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#alphafold3" id="toc-alphafold3" class="nav-link active" data-scroll-target="#alphafold3"><span class="header-section-number">11.1</span> Alphafold3</a></li>
  <li><a href="#diffusion-models" id="toc-diffusion-models" class="nav-link" data-scroll-target="#diffusion-models"><span class="header-section-number">11.2</span> Diffusion models</a>
  <ul class="collapse">
  <li><a href="#diffusion-reverse-model-architecture" id="toc-diffusion-reverse-model-architecture" class="nav-link" data-scroll-target="#diffusion-reverse-model-architecture"><span class="header-section-number">11.2.1</span> Diffusion reverse model architecture</a></li>
  <li><a href="#diffusion-model-for-contact-maps" id="toc-diffusion-model-for-contact-maps" class="nav-link" data-scroll-target="#diffusion-model-for-contact-maps"><span class="header-section-number">11.2.2</span> Diffusion model for contact maps</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter1_Proteins.html">Proteins</a></li><li class="breadcrumb-item"><a href="./Chapter5_Proteins.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Integrated protein diffusion language models</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Integrated protein diffusion language models</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Abstract
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this chapter, we’ll discuss AlphaFold3 and its joint sequence (language model like) &amp; diffusion (Image generation model like) architecture. But because AF3 is a truly complex model, we’ll use a far simple protein contact diffusion model, guided by a protein language model.</p>
<p>In doing so we’ll cover and study three core deeplearning concepts, 1. denoising diffusion 2. guided diffusion and 3. cross attention (the actual link between sequences and 3D molecules). The code used for this chapter is found here: <a href="#0" class="uri">https://github.com/MichelNivard/Biological-language-models/tree/main/scripts/Proteins/Chapter11</a></p>
</div>
</div>
<section id="alphafold3" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="alphafold3"><span class="header-section-number">11.1</span> Alphafold3</h2>
<p>Alphafold3<span class="citation" data-cites="abramson2024a">(<a href="references.html#ref-abramson2024a" role="doc-biblioref">Abramson et al. 2024a</a>)</span> has what initially looks like a very complex architecture (See <strong>Figure 1</strong>), at least it did to me for the longest time.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-33.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 1:</strong> (source: Figure 1d Alphafold paper<span class="citation" data-cites="abramson2024b">(<a href="references.html#ref-abramson2024b" role="doc-biblioref">Abramson et al. 2024b</a>)</span>) which abstracts the model architecture used in Alphafold3. We’ll talk trough hings step by step below.</figcaption>
</figure>
</div>
<p>One important new aspect to the architecture is the “Diffusion module” on the bottom right. It has 3 inputs, the results from three other model elements feed into it (blue paths) and a weird little point cloud. The actual architecture of AF3 is really remarkably complex, I feel in no way competent to teach it. Onew of the best overviews I saw is a <a href="https://elanapearl.github.io/blog/2024/the-illustrated-alphafold/">blog post by Elena Simon &amp; Jake Silberg</a>. Like AF2 before it AF3 is a model that impose evolutionarily sensible (the multiple sequence alignments) and geometric (triangle rules) constraint that means their models are tailored/specific/supervised/slower but often better the pure protein language models (at the expense of speed and efficiency).</p>
<p>Because I cant do the full complexity of AF3 justice, but I think I can get people up to speed on how you’d begin to think bridging protein sequence models, and 2D and 3D representation of proteins we are going to train a protein diffusion model, that is guided by the inputs with a generic protein language model ( <code>EvolutionaryScale/esmc-300m-2024-12</code> to be precise, ESM2’s successor) and attaches a diffusion model to it.</p>
<p>Now since I don’t have the compute that google deepmind has (and neither do you…), we’ll train a 2D diffusion model that, guided by a pre-existing protein language model, generates protein contact maps. The reason to again work on predicting contact maps is that 1. the image like illustrations contact maps are help me effectively convey the concept of diffusion and 2. abstracting away the highly effective MSA and physics based architecture in AF3 lets me focus on something fairly profound 9I think: <strong>cross-attention</strong>. To my simple statistics/numerically minded brain the fact that through encoding and attention we can capture the correlations between sequences of tokens is already a huge leap. When I think about how to capture two entirely separate (but related) modalities, a sequence of tokenized amino acids, and the 3-D (or 2D) structure of the molecule, my brain breaks a little. Cross attention is how ChatGPT can relate your written command (“make a picture of a dog strapped to the roof of Mittt Romney’s car, in the style of Studi Ghibli”) and produce an image of just that scene, to the incredible annoyance and in some cases despair of artists who’s work they pirated for that! Fortunately for us, in Genomics the data is actually int the public domain! and so there are no moral compromises to what we are about to do in that respect!</p>
</section>
<section id="diffusion-models" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="diffusion-models"><span class="header-section-number">11.2</span> Diffusion models</h2>
<p>Gaussian Denoising DIffusion models are a very flexible, and ingenious, class of deep learning models for images. Architectures derived form diffusion models the conceptual basis for all kinds of famous image generation models, like the one integrated into ChatGPT or other image generation AI models.</p>
<p>Diffusion models have two parts, a <em>forward</em> process, which is defined, or fixed, and a <em>reverse</em> process which takes the form of a neural network and which is learned. The forward process takes training images (in our case of protein distance maps) and adds sequentially more noise (See Figure 2).</p>
<p>The relation between the image (x) at time t, and t-1 is:</p>
<p><span class="math display">\[
X_{t-1} =  b_0 * X_{t} + b_1 * \mathcal{N}(\mu,\sigma)
\]</span></p>
<p>Where <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are parameterized in a clever way, such that they 1. depend on t alone and 2. the variance of the total image stays the same, or is controlled. This means that we don’t have to store/create all $X_{t-1} $ images bu can reconstruct them from t and the input image <span class="math inline">\(X_0\)</span>. For a specific protein contact map ( <span class="math inline">\(X_0\)</span> )the “noising” sequence might look a little like <strong>figure 2</strong>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-35.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 2</strong>: Denoising diffusion forward process</figcaption>
</figure>
</div>
<p>A diffusion model uses the, and the value of <span class="math inline">\(t\)</span> to learn to “denoise” the image. It doesn’t denoise ithe image all at once though, it trains to denoise from t=500 to t=499, and t=150 to t=149 etc etc. During braining the images are embedded with their specific timestep <span class="math inline">\(t\)</span> such that the <em>reverse</em> diffusion model (generally a U-Net architecture) can learn weights that are able to optimally estimate (and the subtract) the noise for. given image at time step t.</p>
<section id="diffusion-reverse-model-architecture" class="level3" data-number="11.2.1">
<h3 data-number="11.2.1" class="anchored" data-anchor-id="diffusion-reverse-model-architecture"><span class="header-section-number">11.2.1</span> Diffusion reverse model architecture</h3>
<p>Each “down block” in a diffusion U-Net starts with a&nbsp;normalization layer, which helps keep the model stable during training by making sure the numbers flowing through the network stay within a reasonable range. Then comes an&nbsp;activation function, like&nbsp;Swish&nbsp;or&nbsp;GELU, which adds flexibility to the model and helps it learn more complex patterns. The core part of the block is a&nbsp;<strong>Conv2D layer</strong>, which looks at small squares of pixels (like 3×3 patches) and learns to summarize what’s in them—kind of like learning to detect edges, textures, or other useful features. A special trick used in diffusion models is the&nbsp;<strong>time embedding</strong>, which tells the model what step of the denoising process it’s on. This time information is turned into numbers and added to the features in the block so the model can behave differently at each step.</p>
<p>After the main part of the down block, there’s a&nbsp;<strong>downsampling layer</strong>&nbsp;that reduces the size of the image (usually by half) so the next layer can focus on a broader view of the picture. This is often done with a&nbsp;strided convolution, which skips over pixels to shrink the height and width while keeping the most important features. Skip connections pass the feature maps from each downsampling stage directly to the matching upsampling stage on the other side of the U. This helps the model keep important details that might be lost during compression, allowing the decoder to reconstruct sharper and more accurate outputs. The goal of downsamling the image is to tend to the same image at different scales, the fine detail in the early layers, the more global structure int he later layers. In the case of protein contact maps the early layers tend to secondary structure: local spatial conformation of the polypeptide backbone, helices, sheets and loops.</p>
<p>In the&nbsp;<strong>middle of the U-Net</strong>, after the deepest downsampling layer, there’s often a&nbsp;<strong>self-attention block</strong>. This layer helps the model understand&nbsp;<strong>global relationships</strong>&nbsp;in the image — for example, connecting far-apart pixels that should be related (like opposite ends of a stripe or outline). Since it operates at the most compressed resolution, it’s efficient but powerful, and it benefits from the time embedding just like the ResBlocks. in the context of protein contact diffusion models the attention learn aspects of the tertiary protein structure.</p>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-726f52a6c0d95bcd0eab" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-726f52a6c0d95bcd0eab">{"x":{"diagram":"\ndigraph diffusion_unet {\n  graph [layout = dot, rankdir = LR, fontsize = 30]\n\n  // Node styles\n  node [shape=box, style=filled, fontname=Helvetica, fontsize=30]\n\n  // Input and encoder\n  input     [label=\"Input Image\\n(1×128×128)\", fillcolor=lightgray]\n  init_conv [label=\"Init Conv\\n(1 → 64)\", fillcolor=lightgray]\n  down1     [label=\"Down Block 1\\nResBlock ×2\\n(64)\", fillcolor=lightblue]\n  down2     [label=\"Down Block 2\\nResBlock ×2\\n(128)\", fillcolor=lightblue]\n  down3     [label=\"Down Block 3\\nResBlock ×2\\n(256)\", fillcolor=lightblue]\n  down4     [label=\"Down Block 4\\nResBlock ×2\\n(512)\", fillcolor=lightblue]\n\n  // Bottleneck\n  mid1      [label=\"Mid Block 1\\nResBlock\\n(512)\", fillcolor=gold]\n  mid_attn  [label=\"Mid Attention\\nSelf-Attn\\n(512)\", shape=ellipse, fillcolor=orange]\n  mid2      [label=\"Mid Block 2\\nResBlock\\n(512)\", fillcolor=gold]\n\n  // Decoder (upsampling path)\n  up4       [label=\"Up Block 4\\nResBlock ×2\\n(512 → 256)\", fillcolor=lightblue]\n  up3       [label=\"Up Block 3\\nResBlock ×2\\n(256 → 128)\", fillcolor=lightblue]\n  up2       [label=\"Up Block 2\\nResBlock ×2\\n(128 → 64)\", fillcolor=lightblue]\n  up1       [label=\"Up Block 1\\nResBlock ×2\\n(64)\", fillcolor=lightblue]\n  final_res [label=\"Final ResBlock\\n(64)\", fillcolor=lightblue]\n  final_conv[label=\"Final Conv\\n(64 → 1)\", fillcolor=lightblue]\n  output    [label=\"Output Image\\n(1×128×128)\", fillcolor=lightgray]\n\n  // Time embedding\n  time_mlp  [label=\"Time MLP\\nSinusoidal + MLP\\n(→ 64/128/256/512)\", shape=hexagon, fillcolor=pink]\n\n  // Flow (encoder → bottleneck → decoder)\n  input     -> init_conv -> down1 -> down2 -> down3 -> down4\n  down4     -> mid1 -> mid_attn -> mid2 -> up4 -> up3 -> up2 -> up1 -> final_res -> final_conv -> output\n\n  // Time embedding connections to all ResBlocks\n  time_mlp -> down1\n  time_mlp -> down2\n  time_mlp -> down3\n  time_mlp -> down4\n  time_mlp -> mid1\n  time_mlp -> mid2\n  time_mlp -> up4\n  time_mlp -> up3\n  time_mlp -> up2\n  time_mlp -> up1\n  time_mlp -> final_res\n\n  // Skip connections across the U\n  down4 -> up4 [style=dashed, color=darkgray]\n  down3 -> up3 [style=dashed, color=darkgray]\n  down2 -> up2 [style=dashed, color=darkgray]\n  down1 -> up1 [style=dashed, color=darkgray]\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p><strong>Up blocks</strong> in a diffusion U-Net are the mirror of the down blocks—they take the compressed features and gradually rebuild the image to its original size. Each up block typically starts by&nbsp;<strong>upsampling</strong>&nbsp;the feature map, usually with a&nbsp;transpose convolution&nbsp;or&nbsp;nearest-neighbor interpolation followed by a Conv2D, which increases the height and width (often doubling them). After upsampling, the block&nbsp;combines the upsampled features with the skip connection&nbsp;from the matching down block, so it has both high-level context and fine details. It then passes this combined input through one or more&nbsp;ResBlocks, just like in the encoder, using normalization, activation, convolutions, and time embedding again to refine the reconstruction.</p>
<p>At the start, the scalar timestep&nbsp;<code>t</code>&nbsp;is turned into a&nbsp;<strong>high-dimensional vector</strong>&nbsp;using a&nbsp;sinusoidal position embedding, and then passed through a small&nbsp;MLP (multi-layer perceptron)&nbsp;to create a learned time embedding. This embedding is then&nbsp;<strong>injected into nearly every ResBlock</strong>&nbsp;in the model — both in the&nbsp;down blocks,&nbsp;up blocks, and&nbsp;middle blocks. Inside each ResBlock, the time embedding is&nbsp;added (broadcasted)&nbsp;to the feature map after a linear layer transforms it to match the number of channels. This allows every part of the network to be conditioned on how much noise it should expect and how aggressively to denoise.</p>
</section>
<section id="diffusion-model-for-contact-maps" class="level3" data-number="11.2.2">
<h3 data-number="11.2.2" class="anchored" data-anchor-id="diffusion-model-for-contact-maps"><span class="header-section-number">11.2.2</span> Diffusion model for contact maps</h3>
<p>As a training set I build 7000 contact maps, based on experimentally validated proteins in the CASP12 set I obtained form the SideChainNet dataset <span class="citation" data-cites="king2021">(<a href="references.html#ref-king2021" role="doc-biblioref">King and Koes 2021</a>)</span>. I do not build strictly binary contact maps, but build images that reflect 9 distances thresholds (see <strong>Figure 3</strong> for an example entry form the training set).</p>
<p>here is the code I use to download the data, and create the individual images.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>mport os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sidechainnet <span class="im">as</span> scn</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> denoising_diffusion_pytorch <span class="im">import</span> Unet, GaussianDiffusion</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> T</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># === PARAMETERS ===</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">"contact_maps_128"</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>max_residues <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>final_image_size <span class="op">=</span> (<span class="dv">128</span>, <span class="dv">128</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>contact_threshold <span class="op">=</span> <span class="fl">8.0</span>  <span class="co"># only used if you want binary maps</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>scale_to_255 <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>distance_clip <span class="op">=</span> <span class="fl">20.0</span>  <span class="co"># max Å distance</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>os.makedirs(output_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># === FUNCTIONS ===</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_contact_map(coords, binary<span class="op">=</span><span class="va">False</span>, threshold<span class="op">=</span><span class="fl">8.0</span>):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes a contact or distance map from 3D Cα coordinates.</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co">        coords (np.ndarray): Shape (L, 3) or (L, A, 3), 3D coordinates.</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co">        binary (bool): Whether to return binary contact map.</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co">        threshold (float): Å distance cutoff for binary maps.</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co">        clip_dist (float): Max distance for clipping and scaling.</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co">        np.ndarray: (L, L) contact or scaled distance map in uint8.</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># extract only Cα coordinates (atom 0 for each residue)</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    ca_coords <span class="op">=</span> coords[:, <span class="dv">0</span>, :]  <span class="co"># shape (L, 3)</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    n_residues <span class="op">=</span> ca_coords.shape[<span class="dv">0</span>]</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    n_missing <span class="op">=</span> np.isnan(ca_coords).<span class="bu">any</span>(axis<span class="op">=</span><span class="dv">1</span>).<span class="bu">sum</span>()</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    frac_missing <span class="op">=</span> n_missing <span class="op">/</span> n_residues</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> frac_missing <span class="op">&gt;</span> <span class="fl">0.10</span>:</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>protein_id<span class="sc">}</span><span class="ss"> skipped: </span><span class="sc">{</span>n_missing<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_residues<span class="sc">}</span><span class="ss"> Cα coords missing (</span><span class="sc">{</span>frac_missing<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.unique(ca_coords, axis<span class="op">=</span><span class="dv">0</span>).shape[<span class="dv">0</span>] <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>protein_id<span class="sc">}</span><span class="ss"> skipped: collapsed structure (identical Cα)"</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n_residues <span class="op">&lt;</span> <span class="dv">10</span>:</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>protein_id<span class="sc">}</span><span class="ss"> skipped: too short (</span><span class="sc">{</span>n_residues<span class="sc">}</span><span class="ss"> residues)"</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize based on first Cα</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    ca_coords <span class="op">-=</span> ca_coords[<span class="dv">0</span>]  <span class="co"># shift so residue 0 is at (0, 0, 0)</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute pairwise distance matrix</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    dists <span class="op">=</span> np.linalg.norm(ca_coords[:, <span class="va">None</span>, :] <span class="op">-</span> ca_coords[<span class="va">None</span>, :, :], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> binary:</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>        contact_map <span class="op">=</span> (dists <span class="op">&lt;</span> threshold).astype(np.uint8) <span class="op">*</span> <span class="dv">255</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> contact_map</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>        levels <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">20</span>,<span class="dv">40</span>,<span class="dv">60</span>,<span class="dv">80</span>,<span class="dv">100</span>,<span class="dv">120</span>,<span class="dv">140</span>,<span class="dv">160</span>,<span class="dv">180</span>]</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>        contact_map <span class="op">=</span> np.zeros_like(dists, dtype<span class="op">=</span>np.uint8) <span class="op">+</span> <span class="dv">255</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Bin 0: d &lt; threshold - 3</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> dists <span class="op">&lt;</span> (threshold <span class="op">-</span> <span class="dv">3</span>)</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>        contact_map[mask] <span class="op">=</span> levels[<span class="dv">0</span>]</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Bins 1 to 9: 1Å slices</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">9</span>):</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>            lower <span class="op">=</span> threshold <span class="op">-</span> <span class="dv">5</span> <span class="op">+</span> (i) </span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>            upper <span class="op">=</span> lower <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>            mask <span class="op">=</span> (dists <span class="op">&gt;=</span> lower) <span class="op">&amp;</span> (dists <span class="op">&lt;</span> upper)</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>            contact_map[mask] <span class="op">=</span> levels[i]</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> contact_map</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Or simply crol the first 128 amino-acids (Ca atoms associated witht hose amino-acids)</span></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crop_contact_map(contact_map, crop_size<span class="op">=</span><span class="dv">256</span>, pad_value<span class="op">=</span><span class="dv">255</span>, min_size<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="co">    Crop the top-left corner of the contact map to (crop_size, crop_size).</span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="co">    Pads with `pad_value` if the map is smaller.</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="co">    Skips maps smaller than `min_size`.</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>    h, w <span class="op">=</span> contact_map.shape</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> h <span class="op">&lt;</span> min_size <span class="kw">or</span> w <span class="op">&lt;</span> min_size:</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Contact map too small: </span><span class="sc">{</span>h<span class="sc">}</span><span class="ss">x</span><span class="sc">{</span>w<span class="sc">}</span><span class="ss"> (min required: </span><span class="sc">{</span>min_size<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>    canvas <span class="op">=</span> np.full((crop_size, crop_size), pad_value, dtype<span class="op">=</span>np.uint8)</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>    crop_h <span class="op">=</span> <span class="bu">min</span>(h, crop_size)</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>    crop_w <span class="op">=</span> <span class="bu">min</span>(w, crop_size)</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>    canvas[:crop_h, :crop_w] <span class="op">=</span> contact_map[:crop_h, :crop_w]</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Image.fromarray(canvas)</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="co"># === MAIN ===</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Loading SideChainNet CASP12 dataset..."</span>)</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> scn.load(casp_version<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Generating contact maps..."</span>)</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, sample <span class="kw">in</span> <span class="bu">enumerate</span>(data):</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>        protein_id <span class="op">=</span> sample.<span class="bu">id</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>        coords <span class="op">=</span> sample.coords  <span class="co"># shape: (L, A, 3)</span></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> coords <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> coords.shape[<span class="dv">0</span>] <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute distance matrix and preprocess</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>        distance_map <span class="op">=</span> make_contact_map(coords, binary<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Skip if it's completely empty</span></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.<span class="bu">all</span>(distance_map <span class="op">==</span> <span class="dv">255</span>):</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Skipping </span><span class="sc">{</span>protein_id<span class="sc">}</span><span class="ss">: distance map is all white"</span>)</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Make the final image</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> crop_contact_map(distance_map, crop_size<span class="op">=</span><span class="dv">128</span>,pad_value<span class="op">=</span><span class="dv">255</span>)</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>        img.save(os.path.join(output_dir, <span class="ss">f"</span><span class="sc">{</span>protein_id<span class="sc">}</span><span class="ss">.jpg"</span>), <span class="bu">format</span><span class="op">=</span><span class="st">'JPEG'</span>)</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"[</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">] Saved: </span><span class="sc">{</span>protein_id<span class="sc">}</span><span class="ss">.jpg"</span>)</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Skipping </span><span class="sc">{</span>sample<span class="sc">.</span><span class="bu">id</span><span class="sc">}</span><span class="ss"> due to error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✅ Done."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This generates a folder with thousands of images of contact maps, where the specific share of grey of the pixel correspond to &lt;4 (black), 5, 6, 7, 8, 9, 10, 11, 12,or &gt;13 (white) Angstrom distances.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/1KZQ_d1kzqb1.jpg" class="img-fluid figure-img" width="444"></p>
<figcaption><strong>Figure 3</strong>: A protein distance map based on experimental CASP12 data.</figcaption>
</figure>
</div>
<section id="detailed-parameter-breakdown-by-module-for-our-model" class="level4" data-number="11.2.2.1">
<h4 data-number="11.2.2.1" class="anchored" data-anchor-id="detailed-parameter-breakdown-by-module-for-our-model"><span class="header-section-number">11.2.2.1</span> <strong>Detailed Parameter Breakdown by Module for our model</strong></h4>
<p>The table below breaks down the different elements of the U-Net architecture of a tiny diffusion model I trained. The table describes how how many free parameters each part of the model contains. as you can see the decoder <code>ups</code> part of the model has almost half of the parameters. This is where the encoded information, and the skip connections are brought together. You’ll also note the most number of parameters in the <code>time_mlp</code> which is the part of the model which encodes the influences of the specific timestep <code>t</code> though its important to realize the the ResBlocks (both in the encoder and decoder) also contain parameters that map the time specif embedding to the image information, those regulated <em>how</em> the time information influences the image generation at each specific stage.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Module</th>
<th>Parameters</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>ups</code></td>
<td>19,832,768</td>
<td><strong>Upsampling path (decoder):</strong>&nbsp;progressively reconstructs the denoised image from compressed features. Includes ResBlocks, upsampling (e.g.&nbsp;transposed convolutions), and skip connections from encoder layers.</td>
</tr>
<tr class="even">
<td><code>downs</code></td>
<td>5,402,816</td>
<td><strong>Downsampling path (encoder):</strong>&nbsp;extracts hierarchical features from the noisy input image using stacked ResBlocks and downsampling layers.</td>
</tr>
<tr class="odd">
<td><code>mid_block1</code></td>
<td>4,983,808</td>
<td><strong>First bottleneck ResBlock:</strong>&nbsp;processes the most compressed latent representation of the input, directly before/after the attention block.</td>
</tr>
<tr class="even">
<td><code>mid_block2</code></td>
<td>4,983,808</td>
<td><strong>Second bottleneck ResBlock:</strong>&nbsp;further transforms latent features after attention at the bottleneck. Acts as a transition before decoding.</td>
</tr>
<tr class="odd">
<td><code>mid_attn</code></td>
<td>264,192</td>
<td><strong>Self-attention at bottleneck:</strong>&nbsp;captures global spatial dependencies in the most compressed feature map, enabling long-range interactions.</td>
</tr>
<tr class="even">
<td><code>final_res_block</code></td>
<td>152,000</td>
<td><strong>Final ResBlock before output:</strong>&nbsp;fuses decoder output and prepares it for the final convolution. Often used to refine the final image prediction.</td>
</tr>
<tr class="odd">
<td><code>time_mlp</code></td>
<td>82,432</td>
<td><strong>Timestep embedding network:</strong>&nbsp;converts scalar timestep into a vector that conditions all ResBlocks, allowing the model to denoise appropriately for each diffusion step.</td>
</tr>
<tr class="even">
<td><code>init_conv</code></td>
<td>3,200</td>
<td><strong>Initial input convolution:</strong>&nbsp;expands the input image from 1 channel to base feature dimension (<code>dim=64</code>), preparing it for downstream processing.</td>
</tr>
<tr class="odd">
<td><code>final_conv</code></td>
<td>65</td>
<td><strong>Final output convolution:</strong>&nbsp;projects the final hidden features back to 1 channel to match the original image shape. Predicts either noise (<code>ε_t</code>) or clean image (<code>x₀</code>).</td>
</tr>
</tbody>
</table>
<p>Once we’ve traned the diffusion model for about 40/60 minutes (though ideally longer and on way more data!) we can sample from it. Sampling form it involves sampling pure gaussian noise (“<code>t - 999</code>”) and pasisng the noise trough the dissuion model a few hundred times (each time updating <code>t</code>). There are speedups and trick that mean you wont have to pass it trought he model 1000 times to get a solid result though more passes (“steps”) generally means a better result. Because protein contact maps are symmetric, but the model doenst know that, I generate a protein but then copy over one of the two halfs. In <strong>Figure 3</strong> I show a particularly convincing looking sample at 5 steps form noise to final protein contact map.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-36.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 3:</strong> interim and final stages of a protein contact map sampled from pure noise, after training for a few epochs on 7000 real proteins.</figcaption>
</figure>
</div>
<p>The protein contact map sampled in <strong>Figure 3</strong> is a fiction that, according to the model, fits the distribution of the training data, which while fascinating isn’t very useful yet. To make things useful we must condition the model on not just timestep, but also on condensed, or embedded sequence information.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-abramson2024a" class="csl-entry" role="listitem">
Abramson, Josh, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, et al. 2024a. <span>“Accurate Structure Prediction of Biomolecular Interactions with AlphaFold 3.”</span> <em>Nature</em> 630 (8016): 493–500. <a href="https://doi.org/10.1038/s41586-024-07487-w">https://doi.org/10.1038/s41586-024-07487-w</a>.
</div>
<div id="ref-abramson2024b" class="csl-entry" role="listitem">
———, et al. 2024b. <span>“Accurate Structure Prediction of Biomolecular Interactions with AlphaFold 3.”</span> <em>Nature</em> 630 (8016): 493–500. <a href="https://doi.org/10.1038/s41586-024-07487-w">https://doi.org/10.1038/s41586-024-07487-w</a>.
</div>
<div id="ref-king2021" class="csl-entry" role="listitem">
King, Jonathan Edward, and David Ryan Koes. 2021. <span>“SidechainNet: An All<span>-</span>Atom Protein Structure Dataset for Machine Learning.”</span> <em>Proteins: Structure, Function, and Bioinformatics</em> 89 (11): 1489–96. <a href="https://doi.org/10.1002/prot.26169">https://doi.org/10.1002/prot.26169</a>.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="MichelNivard/Biological-language-models" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Chapter4_Proteins.html" class="pagination-link" aria-label="Protein contact maps from attention maps">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Protein contact maps from attention maps</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./summary.html" class="pagination-link" aria-label="Summary">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Summary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>