<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Proteins: from sequence to structure – Biological Language Models &amp; Neural Networks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Chapter2_Proteins.html" rel="next">
<link href="./Scaling_training.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e84559ba8659b1a571faa725acb99328.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./DNA.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Biological Language Models &amp; Neural Networks</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter1_Proteins.html">Proteins</a></li><li class="breadcrumb-item"><a href="./Chapter1_Proteins.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Proteins: from sequence to structure</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Preamble1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is this Book About?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Preamble2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Read this Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Preamble3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The software stack</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">DNA</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter1_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preparing DNA data for training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter2_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Training our first DNA Language Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter3_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Evaluating DNA Language Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter4_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Evolution-Aware Encoders</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter5_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Comparing Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter6_DNA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">A Review of Current DNA Language Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Scaling_training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Scale up Training {.unnumbered}</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Proteins</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter1_Proteins.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Proteins: from sequence to structure</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter2_Proteins.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Selecting and curating protein sequences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter3_Proteins.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Training our first Protein Language Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter4_Proteins.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Protein contact maps from attention maps</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter5_Proteins.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Integrated protein diffusion language models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Multi-Modal-Biology</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#traditional-approaches-to-protein-structure-prediction" id="toc-traditional-approaches-to-protein-structure-prediction" class="nav-link active" data-scroll-target="#traditional-approaches-to-protein-structure-prediction"><span class="header-section-number">8.1</span> Traditional Approaches to Protein Structure Prediction</a></li>
  <li><a href="#the-critical-breakthrough-alphafold" id="toc-the-critical-breakthrough-alphafold" class="nav-link" data-scroll-target="#the-critical-breakthrough-alphafold"><span class="header-section-number">8.2</span> The critical breakthrough: AlphaFold</a>
  <ul class="collapse">
  <li><a href="#good-old-msa" id="toc-good-old-msa" class="nav-link" data-scroll-target="#good-old-msa"><span class="header-section-number">8.2.1</span> Good old MSA</a></li>
  </ul></li>
  <li><a href="#the-leap-to-protein-language-models" id="toc-the-leap-to-protein-language-models" class="nav-link" data-scroll-target="#the-leap-to-protein-language-models"><span class="header-section-number">8.3</span> The Leap to Protein Language Models</a>
  <ul class="collapse">
  <li><a href="#protein-language-models-as-biologically-tokenized-dna-language-models" id="toc-protein-language-models-as-biologically-tokenized-dna-language-models" class="nav-link" data-scroll-target="#protein-language-models-as-biologically-tokenized-dna-language-models"><span class="header-section-number">8.3.1</span> Protein language models as biologically tokenized DNA language models</a></li>
  </ul></li>
  <li><a href="#step-by-step-1d-sequences-to-3d-structures" id="toc-step-by-step-1d-sequences-to-3d-structures" class="nav-link" data-scroll-target="#step-by-step-1d-sequences-to-3d-structures"><span class="header-section-number">8.4</span> Step by Step: 1D Sequences to 3D Structures</a></li>
  <li><a href="#weird-and-wonderful-protein-model-variants" id="toc-weird-and-wonderful-protein-model-variants" class="nav-link" data-scroll-target="#weird-and-wonderful-protein-model-variants"><span class="header-section-number">8.5</span> Weird and wonderful protein model variants</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter1_Proteins.html">Proteins</a></li><li class="breadcrumb-item"><a href="./Chapter1_Proteins.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Proteins: from sequence to structure</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ProtIntro" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Proteins: from sequence to structure</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Proteins are the fundamental building blocks of biological systems, and understanding their structure is crucial for deciphering their function. The journey from a one-dimensional (1D) amino acid sequence to a two-dimensional (2D) contact map/distance map and finally to a three-dimensional (3D) structure has been one of the grand challenges in computational biology. In this chapter, we explore how protein models based on attention/transformer-like modules, like AlphaFold and ESMfold(2)<span class="citation" data-cites="lin2023">(<a href="references.html#ref-lin2023" role="doc-biblioref">Lin et al. 2023</a>)</span>, revolutionized this space. Though we should not from the start, that models which are aware of multiple sequences alignment (MSA) during training, that are supervised to understand evolutionary constraint (i.e learn what can and cannot easily change in a protein) are VERY hard to beat for pure Protein language Models. Those MSA aware models, specifically Alphafold and Alphafold2<span class="citation" data-cites="jumper2021">(<a href="references.html#ref-jumper2021" role="doc-biblioref">Jumper et al. 2021</a>)</span> won their developers a Nobel Price in medicine. Befoe you dive into these chapters on protein models, its worth watching this vertasium video titled “<a href="https://www.youtube.com/watch?v=P_fHJIYENdI">The most useful thing AI has ever done</a>” as a way of easing into the topic. one elephant in the room is that protein language models, which do not rely on MSA, have struggled greatly to beat much smaller protein models that directly incorporate MSA, so always evaluate the pro’s/con’s of different architectures for your specific research questions &amp; needs!</p>
<section id="traditional-approaches-to-protein-structure-prediction" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="traditional-approaches-to-protein-structure-prediction"><span class="header-section-number">8.1</span> Traditional Approaches to Protein Structure Prediction</h2>
<p>Before the advent of language models and sophisticated deep learning architectures, protein structure prediction relied heavily on physics-based models and evolutionary information encoded in multiple sequence alignments (MSAs). Homology modeling, one of the earliest techniques, used the structures of similar, evolutionarily related proteins to infer the structure of a target protein. Threading methods aligned sequences against known structures to find the best possible fold. Ab initio modeling, in contrast, attempted to predict protein structure from first principles, using physical energy functions to simulate the folding process. These methods often struggled with accuracy and required extensive computational resources, making them impractical for many real-world applications.</p>
</section>
<section id="the-critical-breakthrough-alphafold" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="the-critical-breakthrough-alphafold"><span class="header-section-number">8.2</span> The critical breakthrough: AlphaFold</h2>
<p>MSA-based models, like those used in the early iterations of AlphaFold and Rosetta, made significant strides by leveraging evolutionary couplings between residues. These statistical relationships, inferred from aligned sequences across species, provided powerful constraints on the possible 3D structures. Coupling information was used to construct 2D contact maps — matrices indicating which amino acid pairs were likely to be spatially close in the folded protein.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-24.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 1:</strong> The progress in protein structure prediction across iterations of CASP, notice the clear breakthroughs AlphaFold and AlphaFold-2 represent.</figcaption>
</figure>
</div>
<p>AlphaFold<span class="citation" data-cites="senior2020">(<a href="references.html#ref-senior2020" role="doc-biblioref">Senior et al. 2020</a>)</span> in CASP13, and AlphaFold 2<span class="citation" data-cites="jumper2021">(<a href="references.html#ref-jumper2021" role="doc-biblioref">Jumper et al. 2021</a>)</span> in CASP 14 were revolutionary. The GDT scores, which are the percentage of atoms within 1, 2, or 8 angstroms (<span class="math inline">\(10^{-10}\)</span> m) of the directly measured protein structure, reached ±90, meaning 90% of the atoms in the prediction were extremely close to the measured protein. The score was referred to as “near experimental accuracy,” though that claim made in the Nature paper was unreferenced. I would love a table with an empirical estimate of the experimental accuracy (from repeated independent measurements of the protein, for example) and the AF2 predictions’ GDT/RMSD side by side (I have not been able to find anything like it, could be my inexperience with the particular field!).</p>
<section id="good-old-msa" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="good-old-msa"><span class="header-section-number">8.2.1</span> Good old MSA</h3>
<p>In our chapters on DNA language models, we came across GPN-MSA <span class="citation" data-cites="Benegas2024">(<a href="references.html#ref-Benegas2024" role="doc-biblioref">Benegas et al. 2023</a>)</span>, which relied on multiple sequence alignment (MSA) between species. We even trained a model that was a lot like it in Chapter 4! As you’ll recall, the model did amazing, but mostly I feel because while masking, we only masked the human base and let the model use all ancestral bases during prediction. The multiple sequence alignments play a big role in the recent success in protein folding.</p>
<p>The logic being that if two amino acids “correlate” or co-occur across species, like column 3 and 9 highlighted in red in <strong>Figure 2</strong>, that indicates their co-evolution. Their co-evolution at distance is then viewed as an indicator of their physical proximity in the 3D molecule. In the toy example, we only observe G and H OR T and V in positions 3 and 9, which means there is likely a fitness penalty against other combinations. If these co-evolution signals are robust (reliably found across many aligned sequences) and at a distance, they likely reflect that the two amino acids are physically close, and the substitution of one has an effect on the binding/function of the other.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Chapter1_Proteins_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption><strong>Figure 2:</strong> Example MSA with a co-evolving pair of amino acids (pos 3 and 9) highlighted in red.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="the-leap-to-protein-language-models" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="the-leap-to-protein-language-models"><span class="header-section-number">8.3</span> The Leap to Protein Language Models</h2>
<p>The success of AlphaFold 2 marked a watershed moment for protein structure prediction. By integrating attention-based neural networks and using MSAs to predict 3D structures directly from sequence information, AF2 achieved unprecedented accuracy. Yet, the reliance on MSAs introduced limitations — the need for evolutionary data and the computational cost of alignment. It even appears that as the datasets, and the models grow explicitly conditioning on MSA becomes less important. AlphaFold3 for example already reduces the importance of MSA related information in the model. that being said, Alphafold2 is a &lt; 100 million parameter model and it handily beats Protein language models ten to twenty times it size at times!</p>
<p>Protein language models (PLMs) now slowly emerge as an alternative that is way cheaer to run, and doesnt require MSA allignment. By pretraining on vast protein databases, PLMs capture contextual information about amino acids and their interactions without needing MSAs. Models like ESM (Evolutionary Scale Modeling)<span class="citation" data-cites="rives2021">(<a href="references.html#ref-rives2021" role="doc-biblioref">Rives et al. 2021</a>)</span>, ESM2<span class="citation" data-cites="lin2023">(<a href="references.html#ref-lin2023" role="doc-biblioref">Lin et al. 2023</a>)</span> and ProtTrans<span class="citation" data-cites="elnaggar2022">(<a href="references.html#ref-elnaggar2022" role="doc-biblioref">Elnaggar et al. 2022</a>)</span> demonstrated the potential of PLMs to predict secondary and tertiary structures directly from sequence data. By encoding the relationships between residues through attention mechanisms, these models implicitly learn structural and functional properties, generating accurate 2D contact maps and even 3D coordinates in some cases.</p>
<p>Protein language models are frequently augmented with geometric neural networks or other additional model “adapters” when used for protein structure prediction. These augmentations ensure the 1D sequences, 2D contact maps, and 3D protein shapes that follow adhere to basic geometric rules. A language model or another sequence model isn’t inherently aware of 3D space. So while we’ll experiment with the latent 2D representations (distances between amino acids) that are implicitly hiding in language models, those representations are noisy and might imply 3D structures that cannot exist (e.g., the distance between a and b, and b and c, might not be consistent with the distance between b and c, etc.). Adding specific neural networks that are designed to produce results that can exist in Euclidean (3D) space greatly improves protein structure prediction. More recent experimentation has linked protein language models directly to diffusion image models to predict protein structure in 3D space with minimal supervision.</p>
<section id="protein-language-models-as-biologically-tokenized-dna-language-models" class="level3" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="protein-language-models-as-biologically-tokenized-dna-language-models"><span class="header-section-number">8.3.1</span> Protein language models as biologically tokenized DNA language models</h3>
<p>We previously considered DNA language models at nucleotide level, and discussed in <a href="Chapter2_DNA.html" class="quarto-xref"><span>Chapter 2</span></a> how tokenization is a key step in designing any language model. A protein language model tokenized at amino-acid model is <em>like</em> a naturally tokenized DNA language model, at least for human coding sequences within the DNA. Its important to realize that while DNA coding sequences faithfully translated to amino-acid sequences, amino-acids cannot be perfectly translated back to DNA sequences given multiple triplet DNA/RNA codon sequences (e.g.&nbsp;<code>GAC</code> and <code>GAU</code>) code for the same amino-acid (in this case <code>Asp</code>). That being said, t a later point in this book (Chapter to be written) we’ll consider “multi-modal” models that can represent an input sequence as DNA, RNA or amino-acids with allowances for the asymmetry of the translation.</p>
</section>
</section>
<section id="step-by-step-1d-sequences-to-3d-structures" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="step-by-step-1d-sequences-to-3d-structures"><span class="header-section-number">8.4</span> Step by Step: 1D Sequences to 3D Structures</h2>
<p>The process of moving from a linear amino acid sequence to a folded protein structure involves multiple steps, and in the following chapters, we’ll trace those steps:</p>
<ol type="1">
<li><p>Data sources: As always, science begins with good data. In <strong>Chapter 8</strong>, we’ll talk about data sources for protein (language) models.</p></li>
<li><p><strong>1D Sequence Representation:</strong> The raw sequence of amino acids, analogous to a string of text in natural language. In <strong>Chapter 9</strong>, we’ll train a protein language model. Since we can’t compete with the likes of Google DeepMind and Facebook, or even startups, and I want it to be feasible for you to run all of the steps at home, we’ll train a small language model on an ad-hoc selection of G-protein coupled receptor (GPCR) (like/related) proteins across hundreds of species. This large protein family (4% of human protein-coding genome, for example) shares evolutionary origins and therefore is probably a ripe target for a small model with limited training budget.</p></li>
<li><p><strong>2D Contact Map Prediction:</strong> For any protein, you can conceive a matrix representation showing which pairs of residues are likely to be spatially close, providing key insights into the folding topology. In <strong>Chapter 10</strong>, we’ll discuss ways in which protein language models (latently!) actually already learn the 2D contact map for each protein, and we’ll extract these from the protein model we trained and compare them to the true contact map for a few proteins. because we’ll dig into the internals of a language model we’ll also have to study <strong>self-attention</strong>, the core “correlational” mechanism in a language model in this chapter.</p></li>
<li><p><strong>3D Structure Construction:</strong> In <strong>Chapter 11</strong>, we’ll look at a few different ways in which we can train models that output a full 3D protein by post-processing the 2D information learned in protein language models. We’ll conceive of 2D structures as images, and 3D structures as simply 3D representations. Deep-learning models for image data have advanced incredibly, and those lessons have been applied to proteins structure modeling. One highly successful guided image modeling technique is <strong>guided-diffusion,</strong> a model where trough adding noise to images in 1000s of small steps, and then training a model to denoise the image one step at a time people have been able to train “generative” models. These models can be augmented with textual (or other) context, so while denoising a golden retriever with a funny hat, the model is provided the embedding, or reduction of the text “Golden retriever with a funny hat”. <strong>Alphafold3</strong><span class="citation" data-cites="abramson2024">(<a href="references.html#ref-abramson2024" role="doc-biblioref">Abramson et al. 2024</a>)</span>, one of the most performant models to date, is essentially a protein language model (slightly augmented with MSA information) where the final information form the language model is used to guide a diffusion model. Because <strong>Alphafold3</strong> is a fairly complex model, we’ll take a stab at training something slightly more abstracted. We;’ll use our own protein model (or <code>facebook/esm2_t33_650M_UR50D</code>) to produce embedding, and by using cross attention between the language model embedding, and the diffusion image model matrices “guide” the construction of 2D contact maps from noise using fairly standard image modeling techniques<span class="citation" data-cites="saharia2022">(<a href="references.html#ref-saharia2022" role="doc-biblioref">Saharia et al. 2022</a>)</span>. Finally, we’ll have code to do the same for 3D protein structure, though training that model will likely exceed the computational facilities I or either of you can easily access. in <strong>Chapter 12</strong> we expand our toy model abstraction of AF3, by conditioning the diffusion model on both 1D sequence embeddings and 2D attention maps.</p></li>
</ol>
</section>
<section id="weird-and-wonderful-protein-model-variants" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="weird-and-wonderful-protein-model-variants"><span class="header-section-number">8.5</span> Weird and wonderful protein model variants</h2>
<p>On the back of the success of Alphfold have come some truly creative models.</p>
<p><strong>Amino-acids to structure and then back to tokens</strong>: In <strong>Chapter 13</strong>, we’ll discuss an interesting class of models that actually mimic nature in a weird way, these models take molecules as input, and condense those into categorical tokens, not amino-acid, but learned tokens trained to represent a hyper efficient geometric alphabet. Foldseek <span class="citation" data-cites="vankempen2023">(<a href="references.html#ref-vankempen2023" role="doc-biblioref">Kempen et al. 2023</a>)</span> and models like it<span class="citation" data-cites="gao2024">(<a href="references.html#ref-gao2024" role="doc-biblioref">Gao, Tan, and Li 2024</a>)</span> <strong>take a 3D structure, and encode that into categorical tokens</strong>, at the same resolution of the amino acids. Then at each base we know amino-acid, its location in 3D space, and a new token that compresses that location in space. This technique, the first of which was known as might sound a little redundant but it gets at an important issue: many very different proteins, in terms of structure, might fold in similar ways, and even serve similar or the same biological function! Furthermore having encoded structure into tokens allows for ultra fast structure similarity search (orders of magnitudes faster then search based on the full 3d molecule). One of the exciting applications these models might have is to train GPT like models on these spatial tokens in order to generate candidate proteins which are likely to fold into a specific shape<span class="citation" data-cites="gaujac2024">(<a href="references.html#ref-gaujac2024" role="doc-biblioref">Gaujac et al. 2024</a>)</span>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-abramson2024" class="csl-entry" role="listitem">
Abramson, Josh, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, et al. 2024. <span>“Accurate Structure Prediction of Biomolecular Interactions with AlphaFold 3.”</span> <em>Nature</em> 630 (8016): 493–500. <a href="https://doi.org/10.1038/s41586-024-07487-w">https://doi.org/10.1038/s41586-024-07487-w</a>.
</div>
<div id="ref-Benegas2024" class="csl-entry" role="listitem">
Benegas, Gonzalo, Carlos Albors, Alan J. Aw, Chengzhong Ye, and Yun S. Song. 2023. <span>“GPN-MSA: An Alignment-Based DNA Language Model for Genome-Wide Variant Effect Prediction.”</span> <a href="http://dx.doi.org/10.1101/2023.10.10.561776">http://dx.doi.org/10.1101/2023.10.10.561776</a>.
</div>
<div id="ref-elnaggar2022" class="csl-entry" role="listitem">
Elnaggar, Ahmed, Michael Heinzinger, Christian Dallago, Ghalia Rehawi, Yu Wang, Llion Jones, Tom Gibbs, et al. 2022. <span>“ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 44 (10): 7112–27. <a href="https://doi.org/10.1109/tpami.2021.3095381">https://doi.org/10.1109/tpami.2021.3095381</a>.
</div>
<div id="ref-gao2024" class="csl-entry" role="listitem">
Gao, Zhangyang, Cheng Tan, and Stan Z. Li. 2024. <span>“FoldToken4: Consistent &amp; Hierarchical Fold Language.”</span> <a href="http://dx.doi.org/10.1101/2024.08.04.606514">http://dx.doi.org/10.1101/2024.08.04.606514</a>.
</div>
<div id="ref-gaujac2024" class="csl-entry" role="listitem">
Gaujac, Benoit, Jérémie Donà, Liviu Copoiu, Timothy Atkinson, Thomas Pierrot, and Thomas D. Barrett. 2024. <span>“Learning the Language of Protein Structure.”</span> <a href="https://doi.org/10.48550/ARXIV.2405.15840">https://doi.org/10.48550/ARXIV.2405.15840</a>.
</div>
<div id="ref-jumper2021" class="csl-entry" role="listitem">
Jumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. <span>“Highly Accurate Protein Structure Prediction with AlphaFold.”</span> <em>Nature</em> 596 (7873): 583–89. <a href="https://doi.org/10.1038/s41586-021-03819-2">https://doi.org/10.1038/s41586-021-03819-2</a>.
</div>
<div id="ref-vankempen2023" class="csl-entry" role="listitem">
Kempen, Michel van, Stephanie S. Kim, Charlotte Tumescheit, Milot Mirdita, Jeongjae Lee, Cameron L. M. Gilchrist, Johannes Söding, and Martin Steinegger. 2023. <span>“Fast and Accurate Protein Structure Search with Foldseek.”</span> <em>Nature Biotechnology</em> 42 (2): 243–46. <a href="https://doi.org/10.1038/s41587-023-01773-0">https://doi.org/10.1038/s41587-023-01773-0</a>.
</div>
<div id="ref-lin2023" class="csl-entry" role="listitem">
Lin, Zeming, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, et al. 2023. <span>“Evolutionary-Scale Prediction of Atomic-Level Protein Structure with a Language Model.”</span> <em>Science</em> 379 (6637): 1123–30. <a href="https://doi.org/10.1126/science.ade2574">https://doi.org/10.1126/science.ade2574</a>.
</div>
<div id="ref-rives2021" class="csl-entry" role="listitem">
Rives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. <span>“Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences.”</span> <em>Proceedings of the National Academy of Sciences</em> 118 (15). <a href="https://doi.org/10.1073/pnas.2016239118">https://doi.org/10.1073/pnas.2016239118</a>.
</div>
<div id="ref-saharia2022" class="csl-entry" role="listitem">
Saharia, Chitwan, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, et al. 2022. <span>“Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding.”</span> <a href="https://doi.org/10.48550/ARXIV.2205.11487">https://doi.org/10.48550/ARXIV.2205.11487</a>.
</div>
<div id="ref-senior2020" class="csl-entry" role="listitem">
Senior, Andrew W., Richard Evans, John Jumper, James Kirkpatrick, Laurent Sifre, Tim Green, Chongli Qin, et al. 2020. <span>“Improved Protein Structure Prediction Using Potentials from Deep Learning.”</span> <em>Nature</em> 577 (7792): 706–10. <a href="https://doi.org/10.1038/s41586-019-1923-7">https://doi.org/10.1038/s41586-019-1923-7</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="MichelNivard/Biological-language-models" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Scaling_training.html" class="pagination-link" aria-label="Scale up Training {.unnumbered}">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Scale up Training {.unnumbered}</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Chapter2_Proteins.html" class="pagination-link" aria-label="Selecting and curating protein sequences">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Selecting and curating protein sequences</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>